{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Petitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(df['reason_category'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = new_df[\"public_petition_text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text): \n",
    "    html_tag=re.compile('<.*?>')\n",
    "    text_no_html = html_tag.sub('', text)\n",
    "    return text_no_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quots(text):\n",
    "    text_only_letters = re.sub('[^\\w\\s]', '', text)\n",
    "    return text_only_letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = word_tokenize(text)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph(text):\n",
    "    morph = MorphAnalyzer()\n",
    "    lemmas = [morph.normal_forms(w)[0] for w in text]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_sw(text):\n",
    "    prepared = [w for w in text if w not in stopwords]\n",
    "    lemm_sentce = ' '.join(prepared)\n",
    "    return lemm_sentce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_mass = {\n",
    "    \"rem_html\" : remove_html,\n",
    "    \"rem_quots\" : remove_quots,\n",
    "    \"tokenize\" : tokenize,\n",
    "    \"morph\" : morph,\n",
    "    \"del_sw\" : del_sw\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_m = [\"rem_html\", \"rem_quots\", \"tokenize\", \"morph\", \"del_sw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(list_m, text):\n",
    "    for i in list_m:\n",
    "        text = [general_mass[i](j) for j in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_text = prepro(list_m=list_m, text=rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['просить убрать снег желательно убрать машина тротуар наладить механизировать уборка снег',\n",
       " 'жблом газон',\n",
       " 'чистить ливневый канализация район дом 21 ул гертовский потоп вода откачивать лично представитель управлять компания ваш сотрудник почистить убрать лёд вдоль бордюр откачать вода первый оттепель снова озеро неисправный сток дорога сливной колодец писать отписка вникнуть проблема просить отремонтировать сток дорога колодец сказать секрет ваш сотрудник это увидеть сток сломать ваш спецтехник который ездить тротуар',\n",
       " 'грязный лифт',\n",
       " 'мусор внутридворовый территория 1й парадный газон улица бабушкин дом 63',\n",
       " 'просить убрать мусор',\n",
       " 'просить убрать надпись',\n",
       " 'разбитый покрытие вход подъезд возможно выходить коляска прогулка опасно',\n",
       " '4 подъезд подход подъезд люк левый правый сторона провал земля мочь чтоть случиться люк земля разрываться',\n",
       " 'ненадлежащий состояние малый архитектурный форма придомовый территория требоваться окраскасмфото',\n",
       " 'убрать',\n",
       " 'адрес санктпетербург улица куйбышев дом 5 литера пара 4 закрасить краска стена дом',\n",
       " 'валяться мусор',\n",
       " 'очень некачественный ремонт место снова глубокий ям',\n",
       " 'грязный двор везде валяться мусор',\n",
       " 'сомнительный рекламный конструкция',\n",
       " 'просьба закрыть люк крайне опасный место человек получаться спасибо',\n",
       " 'сломать доводчик дверь чёрный лестница 3 этаж 8 парадный',\n",
       " 'декабрист завал всё протяжение театральный пл пряжка',\n",
       " 'работать уличный фонарь 6 парадный дом 2 корпус 3 ул бела кун',\n",
       " 'повреждение дорожный покрытие',\n",
       " 'неисправный доводчик входной дверь 3 парадный',\n",
       " 'реклама',\n",
       " 'разбитый дорога множество ям возле жк академпарк',\n",
       " 'мусор',\n",
       " 'надпись трансформаторный подстанция',\n",
       " 'мусор вид покрышка нужно убрать',\n",
       " 'мусор газон тротуар убираться',\n",
       " 'граффити',\n",
       " 'самовольно заложить оконный проём',\n",
       " 'грязный лоток',\n",
       " 'мусор вид песок окурок газон',\n",
       " 'периметр дом многочисленный место несанкционированный надпись требоваться привести стена дом надлежащий состояние',\n",
       " 'центр петербург совершенно отвратительный висеть реклама который портить облик невский проспект занимать пол здание мелькать уродовать исторический здание это просто возмутительно ужасный вывеска видно это истрический памятникай здание пассаж видно глаз слепить реклама вместо тогочтоба наслаждаться архитектурный красота гражданин гость глаз рябить это оранжевый чудовище магазин dns невский пр46',\n",
       " 'организовать рынок несколько машина хранение',\n",
       " 'огромный лужа весь тротуар',\n",
       " 'яма асфальтовый покрытие просить провести ремонт последний',\n",
       " 'мусор рядом детский площадка',\n",
       " 'мусор',\n",
       " 'рисунок',\n",
       " 'необходимый ремонт собор рушиться краска штукатурка',\n",
       " 'четвёртый парадный обеспечить плотный притвор входной металлический дверь парадный',\n",
       " 'зелёный красный гореть одновременно',\n",
       " 'самовольно установить решётка лицевой фасад',\n",
       " 'крыса квартира обращаться ук 004 результат неизменный крыса дом квартира xxxxx xxxxxx xxxxxxx xxxxxxxxxxx x xxxxxxxxxxxxx xxxx xxxxxxxxxx xxxxxxx xxxxxxx xxxxx xxxx xxx xxxxx xx xxxxxxxx xxxxxxxxxx xxxxxx xxxxx',\n",
       " 'валяться мусор',\n",
       " 'запах канализация высокий влажность подъезд 7',\n",
       " 'проверить наличие разрешение рекламный конструкция',\n",
       " 'подъезд очень грязно уборка производиться график уборка соблюдаться',\n",
       " 'незаконный торговля прекращаться администрация центральный район справляться свой работа',\n",
       " '9 этаж деформировать потолочный плита рядом элщиток возле кв xxx трещина отходить штукатурка стена кв xxx x xxxxxx пробить потолочный плита рядом вентрешётка возле кв xxxx сдвинуть плита возле пожарный стояк кв xxxx мусорный отсек напротив кв xxx провисать кабель ук эгс бездействовать',\n",
       " 'момент сдача дом мыть окно подоконник просить 9 этаж 7 подъезд рядом кв xxx провести мытьё окно удалить оконный рама строительный краска намыть подоконник',\n",
       " 'очистить',\n",
       " 'реклама',\n",
       " 'мусорный площадка ограждение мусор разлетаться весь двор нужно защитный ограждение',\n",
       " 'песок листва',\n",
       " 'необходимый ремонт плинтус 4 этаж',\n",
       " 'просить закрасить граффити',\n",
       " 'просить убрать мусор',\n",
       " 'граффити реклама незаконный деятельность несколько место вдоль весь фасад жилой дом адрес ул руднева 13 санктпетербург сторона проезжий часть ул руднева актёрский прот',\n",
       " 'незаконный объявление стенд просьба привести нормативный состояние',\n",
       " 'снег потолок появиться след чердак сильно заметный влажный пятно парадный номер 1',\n",
       " 'снег сгрести куча оставить лето видимо',\n",
       " 'выбоина проезжий часть требоваться произвести работа качественный ремонт асфальтовый покрытие карта соблюдать технология фотофиксация 2910прилагаться',\n",
       " 'неочищенный урна',\n",
       " 'полный лестница песок улицть мыть давно пол всё это идти квартира благодатный 29 3 подъезд',\n",
       " 'тамбур подъезд 3 дверь храниться мебель дверь лестница полностью открыть мешать проход мебель просто переместить часть тамбур закинуть электрощит',\n",
       " 'надпись киоск',\n",
       " 'снег тротуар',\n",
       " 'надпись стена сооружение просить убрать',\n",
       " 'бросить полуразобрать легковой автомобиль бульвар красный зоря дом 7',\n",
       " 'просить заменить повредить подоконник помещение черновой лестница лифтовый холл 8 этаж 10 парадный',\n",
       " 'отсутствовать разметка футбольный поле необходимо нанести',\n",
       " 'объявление опор освещение',\n",
       " 'вместо ручка входной дверь подъезд снаружи приварить арматура ответ предыдущий сообщение ук привинтить ручка внутри подъезд сфотографировать отписаться проблема решить арматура попрежний место ручка попрежний отсутствовать',\n",
       " 'убрать',\n",
       " 'дверь лифт закрываться скрежет 9 этаж 9 парадный остановка лифт подпрыгивать протяжение месяц подавать заявка обслуживающий компания никто принимать мера',\n",
       " 'двор стоять мусорный контейнер прямо окно жилой квартира просить проверить правомерность установка данные контейнер весь запах идти окно невозможно проветрить',\n",
       " 'добрый вечер наблюдаться постоянный проблема уборка лестничный площадка график соблюдаться каждый месяц уборка производиться звонок жалоба просить наладить работа впредь дожидаться звонок убрать подъезд',\n",
       " 'посторонний надпись знак пешеходный переход',\n",
       " 'двор дом адресуогородный пер 6к1 сделать прекрасный газон который вытоптать любитель собака питомец фекалия животное газон видимоневидимо просить установить ограждение весь газон весь сторона двор огородить цветник около дом',\n",
       " 'неисправный освещение фасад нежилой здание нужно заменить старый неисправный проржаветь уличный светильник разбитый лампа плафон современный светильник восстановить освещение',\n",
       " 'листва земля',\n",
       " 'двор чиститься снег',\n",
       " 'убирать снег убирать снег уборка производиться указанный день ждать снег растаетфото сделать ракурс сугроб уборка производиться',\n",
       " 'работать лампа фасад дом',\n",
       " 'просить восстановить дверца щит 4 этаж 13 парадный',\n",
       " 'надпись стена',\n",
       " 'убрать снег тротуар',\n",
       " 'просить убрать реклама',\n",
       " 'лист мешок',\n",
       " 'добрый день фасад дом облицевать натуральный камень перекрытие надпись объявление краска являться нарушение архитектурный замысел портить внешний вид дом просить произвести очистка указанный фасад помощь пескоструить восстановить первоначальный вид дом фото дом сделать сторона кораблестроитель подъезд 3',\n",
       " 'сломать дверь контейнерный площадка',\n",
       " 'добрый день паркинг неисправный вентель который течь вода машина место 601 первый уровень заявка оставить управлять компания ещё пятница 20112020 сделановод продолжать капать видео',\n",
       " 'реклама опор освещёние',\n",
       " 'здравсвовать дом ул коломенский 28 убрать территория снег нужно убрать',\n",
       " 'огромный ям дорога',\n",
       " 'качественно отмыть фекалия почтовый ящик середина лифтовый холл первый этаж отмыть пыль почтовый ящик тамбур управлять компания бездействовать',\n",
       " 'самовольный камера видео наблюдение',\n",
       " 'просить сделать чтоть дорога отличный дорогой постройка новый элитный жк ездить невозможно']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['лист',\n",
       " 'листва',\n",
       " 'площадка',\n",
       " 'заложить',\n",
       " 'давно',\n",
       " 'рама',\n",
       " 'гореть',\n",
       " 'фекалия',\n",
       " 'вместо',\n",
       " 'куча',\n",
       " 'контейнер',\n",
       " 'светильник',\n",
       " 'протяжение',\n",
       " 'лифт',\n",
       " 'проверить',\n",
       " 'актёрский',\n",
       " 'яма',\n",
       " 'рябить',\n",
       " 'спецтехник',\n",
       " '4',\n",
       " 'район',\n",
       " 'наблюдение',\n",
       " 'покрытие',\n",
       " 'бездействовать',\n",
       " '63',\n",
       " 'проспект',\n",
       " 'опасно',\n",
       " 'подпрыгивать',\n",
       " 'продолжать',\n",
       " 'закрыть',\n",
       " 'сообщение',\n",
       " 'жблом',\n",
       " 'реклама',\n",
       " 'середина',\n",
       " 'строительный',\n",
       " 'разбитый',\n",
       " 'обеспечить',\n",
       " 'отписаться',\n",
       " 'сгрести',\n",
       " 'самовольный',\n",
       " 'писать',\n",
       " 'цветник',\n",
       " 'xxxxxxxxxxxxx',\n",
       " 'притвор',\n",
       " 'элщиток',\n",
       " 'ужасный',\n",
       " 'бабушкин',\n",
       " 'фасад',\n",
       " 'проём',\n",
       " '5',\n",
       " 'разрываться',\n",
       " 'отличный',\n",
       " 'xxxxxxxxxx',\n",
       " 'асфальтовый',\n",
       " 'который',\n",
       " 'повреждение',\n",
       " 'правый',\n",
       " 'бела',\n",
       " 'дорожный',\n",
       " 'хранение',\n",
       " 'обращаться',\n",
       " 'урна',\n",
       " '8',\n",
       " 'заметный',\n",
       " 'пятница',\n",
       " 'необходимый',\n",
       " 'дом',\n",
       " 'сотрудник',\n",
       " 'соблюдать',\n",
       " '28',\n",
       " 'решётка',\n",
       " 'xxxxx',\n",
       " 'окраскасмфото',\n",
       " 'администрация',\n",
       " 'управлять',\n",
       " 'трансформаторный',\n",
       " 'открыть',\n",
       " 'парадный',\n",
       " 'сугроб',\n",
       " 'лестничный',\n",
       " 'огромный',\n",
       " 'плинтус',\n",
       " 'лифтовый',\n",
       " 'мешок',\n",
       " 'внутридворовый',\n",
       " 'часть',\n",
       " 'проезжий',\n",
       " 'несанкционированный',\n",
       " 'элитный',\n",
       " 'это',\n",
       " 'почистить',\n",
       " 'растаетфото',\n",
       " 'краска',\n",
       " 'решить',\n",
       " 'правомерность',\n",
       " 'кабель',\n",
       " 'фотофиксация',\n",
       " 'произвести',\n",
       " 'перекрытие',\n",
       " 'руднева',\n",
       " 'некачественный',\n",
       " 'занимать',\n",
       " 'повредить',\n",
       " 'валяться',\n",
       " 'убирать',\n",
       " 'состояние',\n",
       " 'новый',\n",
       " 'требоваться',\n",
       " 'привинтить',\n",
       " 'квартира',\n",
       " 'производиться',\n",
       " 'разметка',\n",
       " 'постоянный',\n",
       " 'проржаветь',\n",
       " 'xxxxxxxx',\n",
       " 'неочищенный',\n",
       " 'старый',\n",
       " 'постройка',\n",
       " 'эгс',\n",
       " 'литера',\n",
       " 'двор',\n",
       " '21',\n",
       " 'стоять',\n",
       " 'оконный',\n",
       " 'напротив',\n",
       " 'люк',\n",
       " 'улицть',\n",
       " 'глаз',\n",
       " 'контейнерный',\n",
       " '004',\n",
       " 'вход',\n",
       " 'вода',\n",
       " 'бульвар',\n",
       " 'установка',\n",
       " 'знак',\n",
       " 'адрес',\n",
       " 'ливневый',\n",
       " 'придомовый',\n",
       " 'автомобиль',\n",
       " 'снаружи',\n",
       " 'лужа',\n",
       " 'день',\n",
       " 'опасный',\n",
       " 'ваш',\n",
       " 'гражданин',\n",
       " 'привести',\n",
       " 'вытоптать',\n",
       " '7',\n",
       " 'разлетаться',\n",
       " 'множество',\n",
       " '1й',\n",
       " 'сделать',\n",
       " 'наладить',\n",
       " 'бросить',\n",
       " 'первоначальный',\n",
       " 'здание',\n",
       " 'вечер',\n",
       " '2910прилагаться',\n",
       " 'ремонт',\n",
       " 'несколько',\n",
       " 'получаться',\n",
       " 'намыть',\n",
       " 'лестница',\n",
       " 'видимоневидимо',\n",
       " 'скрежет',\n",
       " 'собака',\n",
       " 'оставить',\n",
       " 'возле',\n",
       " 'месяц',\n",
       " 'одновременно',\n",
       " 'портить',\n",
       " '9',\n",
       " 'установить',\n",
       " 'нормативный',\n",
       " 'потоп',\n",
       " 'закрываться',\n",
       " 'прекрасный',\n",
       " 'проветрить',\n",
       " 'видимо',\n",
       " 'тогочтоба',\n",
       " 'электрощит',\n",
       " 'кораблестроитель',\n",
       " 'наслаждаться',\n",
       " 'мытьё',\n",
       " 'храниться',\n",
       " '29',\n",
       " 'сделановод',\n",
       " 'здравсвовать',\n",
       " 'рынок',\n",
       " 'чердак',\n",
       " 'необходимо',\n",
       " 'пыль',\n",
       " 'откачать',\n",
       " 'первый',\n",
       " 'ручка',\n",
       " 'освещёние',\n",
       " 'благодатный',\n",
       " 'подстанция',\n",
       " 'уборка',\n",
       " 'капать',\n",
       " 'качественный',\n",
       " 'снег',\n",
       " 'ограждение',\n",
       " 'колодец',\n",
       " 'момент',\n",
       " 'корпус',\n",
       " 'всё',\n",
       " 'оттепель',\n",
       " 'график',\n",
       " 'озеро',\n",
       " 'коляска',\n",
       " 'потолочный',\n",
       " 'номер',\n",
       " 'очень',\n",
       " '1',\n",
       " 'подъезд',\n",
       " 'вдоль',\n",
       " 'плотный',\n",
       " 'чиститься',\n",
       " 'стенд',\n",
       " 'убрать',\n",
       " 'невский',\n",
       " 'след',\n",
       " 'снова',\n",
       " 'мыть',\n",
       " 'самовольно',\n",
       " 'плафон',\n",
       " 'натуральный',\n",
       " 'подавать',\n",
       " 'форма',\n",
       " 'кун',\n",
       " 'зелёный',\n",
       " 'стена',\n",
       " 'переместить',\n",
       " 'обслуживающий',\n",
       " 'x',\n",
       " 'ненадлежащий',\n",
       " 'объявление',\n",
       " 'представитель',\n",
       " 'жк',\n",
       " 'нарушение',\n",
       " 'песок',\n",
       " 'жилой',\n",
       " 'секрет',\n",
       " 'рекламный',\n",
       " 'трещина',\n",
       " 'запах',\n",
       " 'коломенский',\n",
       " 'выбоина',\n",
       " 'просьба',\n",
       " 'облицевать',\n",
       " 'дожидаться',\n",
       " 'высокий',\n",
       " 'гертовский',\n",
       " 'добрый',\n",
       " 'рисунок',\n",
       " 'проход',\n",
       " 'почтовый',\n",
       " 'уродовать',\n",
       " 'xxxxxx',\n",
       " 'просто',\n",
       " 'возможно',\n",
       " 'очистка',\n",
       " 'сооружение',\n",
       " 'пятно',\n",
       " 'красный',\n",
       " 'архитектурный',\n",
       " 'сток',\n",
       " 'центральный',\n",
       " 'механизировать',\n",
       " 'закрасить',\n",
       " 'весь',\n",
       " 'посторонний',\n",
       " 'окно',\n",
       " 'санктпетербург',\n",
       " 'организовать',\n",
       " 'любитель',\n",
       " 'полуразобрать',\n",
       " 'академпарк',\n",
       " 'прекращаться',\n",
       " 'фото',\n",
       " 'замысел',\n",
       " 'переход',\n",
       " 'откачивать',\n",
       " 'висеть',\n",
       " 'вид',\n",
       " 'освещение',\n",
       " 'легковой',\n",
       " 'помощь',\n",
       " 'многочисленный',\n",
       " 'современный',\n",
       " 'доводчик',\n",
       " 'убираться',\n",
       " 'пр46',\n",
       " 'заявка',\n",
       " 'данные',\n",
       " 'прот',\n",
       " 'куйбышев',\n",
       " 'мера',\n",
       " 'заменить',\n",
       " 'приварить',\n",
       " 'xxxx',\n",
       " '6к1',\n",
       " 'вентель',\n",
       " 'каждый',\n",
       " 'везде',\n",
       " 'конструкция',\n",
       " 'плита',\n",
       " 'невозможно',\n",
       " 'питомец',\n",
       " 'грязный',\n",
       " 'декабрист',\n",
       " 'отремонтировать',\n",
       " 'гость',\n",
       " 'человек',\n",
       " 'сильно',\n",
       " 'мусор',\n",
       " 'ям',\n",
       " 'являться',\n",
       " 'последний',\n",
       " 'крыса',\n",
       " 'отмыть',\n",
       " 'нужно',\n",
       " 'футбольный',\n",
       " 'провал',\n",
       " 'принимать',\n",
       " 'прогулка',\n",
       " 'ездить',\n",
       " 'камень',\n",
       " 'тамбур',\n",
       " 'закинуть',\n",
       " 'сомнительный',\n",
       " 'xxxxxxxxxxx',\n",
       " 'увидеть',\n",
       " 'провести',\n",
       " 'технология',\n",
       " 'вывеска',\n",
       " 'карта',\n",
       " 'разрешение',\n",
       " 'стояк',\n",
       " 'отсутствовать',\n",
       " 'ответ',\n",
       " 'пешеходный',\n",
       " 'видно',\n",
       " 'паркинг',\n",
       " 'соблюдаться',\n",
       " 'лампа',\n",
       " 'этаж',\n",
       " 'dns',\n",
       " 'улица',\n",
       " 'качественно',\n",
       " 'проблема',\n",
       " 'периметр',\n",
       " 'левый',\n",
       " 'результат',\n",
       " 'сторона',\n",
       " '6',\n",
       " 'незаконный',\n",
       " 'работать',\n",
       " 'сдача',\n",
       " 'защитный',\n",
       " 'завал',\n",
       " 'земля',\n",
       " 'фонарь',\n",
       " '601',\n",
       " 'граффити',\n",
       " 'указанный',\n",
       " 'слепить',\n",
       " 'ракурс',\n",
       " 'пл',\n",
       " 'попрежний',\n",
       " 'подход',\n",
       " 'мусорный',\n",
       " 'ул',\n",
       " 'облик',\n",
       " 'рядом',\n",
       " 'желательно',\n",
       " 'мелькать',\n",
       " 'влажность',\n",
       " 'адресуогородный',\n",
       " 'пара',\n",
       " 'собор',\n",
       " 'около',\n",
       " 'чтоть',\n",
       " 'наличие',\n",
       " 'мочь',\n",
       " 'дорогой',\n",
       " 'отходить',\n",
       " 'камера',\n",
       " 'восстановить',\n",
       " 'нежилой',\n",
       " 'театральный',\n",
       " 'идти',\n",
       " 'металлический',\n",
       " 'подоконник',\n",
       " 'окурок',\n",
       " 'компания',\n",
       " 'полностью',\n",
       " 'сливной',\n",
       " 'черновой',\n",
       " 'удалить',\n",
       " 'выходить',\n",
       " 'видео',\n",
       " 'памятникай',\n",
       " '3',\n",
       " 'исторический',\n",
       " 'влажный',\n",
       " 'животное',\n",
       " '20112020',\n",
       " 'рушиться',\n",
       " 'течь',\n",
       " 'истрический',\n",
       " 'холл',\n",
       " 'машина',\n",
       " 'центр',\n",
       " '10',\n",
       " 'уличный',\n",
       " 'деформировать',\n",
       " 'отсек',\n",
       " 'жалоба',\n",
       " 'ещё',\n",
       " 'пассаж',\n",
       " 'киоск',\n",
       " 'внутри',\n",
       " 'появиться',\n",
       " '2',\n",
       " '13',\n",
       " 'лето',\n",
       " 'территория',\n",
       " 'поле',\n",
       " 'надлежащий',\n",
       " 'торговля',\n",
       " 'пескоструить',\n",
       " 'тротуар',\n",
       " 'спасибо',\n",
       " 'деятельность',\n",
       " 'бордюр',\n",
       " 'лично',\n",
       " 'очистить',\n",
       " 'дорога',\n",
       " 'просить',\n",
       " 'xxx',\n",
       " 'крайне',\n",
       " 'канализация',\n",
       " 'оранжевый',\n",
       " 'малый',\n",
       " 'потолок',\n",
       " 'звонок',\n",
       " 'нанести',\n",
       " 'вентрешётка',\n",
       " 'щит',\n",
       " 'газон',\n",
       " 'чистить',\n",
       " 'отвратительный',\n",
       " 'xxxxxxx',\n",
       " 'свой',\n",
       " 'четвёртый',\n",
       " 'отписка',\n",
       " 'уровень',\n",
       " 'пожарный',\n",
       " 'место',\n",
       " 'сломать',\n",
       " 'лицевой',\n",
       " 'пробить',\n",
       " 'совершенно',\n",
       " 'ждать',\n",
       " 'красота',\n",
       " 'неизменный',\n",
       " 'арматура',\n",
       " 'чудовище',\n",
       " 'пер',\n",
       " 'огородить',\n",
       " 'надпись',\n",
       " 'чёрный',\n",
       " 'наблюдаться',\n",
       " 'магазин',\n",
       " 'петербург',\n",
       " 'дверь',\n",
       " 'глубокий',\n",
       " 'грязно',\n",
       " 'никто',\n",
       " 'сдвинуть',\n",
       " 'помещение',\n",
       " 'полный',\n",
       " 'опор',\n",
       " 'случиться',\n",
       " 'покрышка',\n",
       " 'пряжка',\n",
       " 'справляться',\n",
       " 'ук',\n",
       " 'лоток',\n",
       " 'входной',\n",
       " 'провисать',\n",
       " 'мешать',\n",
       " 'предыдущий',\n",
       " 'дверца',\n",
       " 'неисправный',\n",
       " 'сказать',\n",
       " 'вникнуть',\n",
       " 'зоря',\n",
       " 'детский',\n",
       " 'штукатурка',\n",
       " 'лёд',\n",
       " 'ящик',\n",
       " 'xx',\n",
       " 'прямо',\n",
       " 'возмутительно',\n",
       " 'кв',\n",
       " 'впредь',\n",
       " 'внешний',\n",
       " 'пол',\n",
       " 'сфотографировать',\n",
       " 'мебель',\n",
       " 'работа',\n",
       " 'остановка']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vocab = set((' '.join(prepro_text).split()))\n",
    "word_to_ix = {word: i for i, word in enumerate(count_vocab)}\n",
    "word_list = list(word_to_ix.keys())\n",
    "word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([440, 220, 201, 376, 220, 413, 433, 152, 269, 198, 201]),\n",
       " tensor([ 31, 451]),\n",
       " tensor([452, 136, 443,  20,  66, 121, 373, 253, 174, 131, 283, 437, 238,  74,\n",
       "         396, 143,  67,  90, 220, 502, 216, 436, 192, 131, 193, 207, 223, 209,\n",
       "         496, 267, 439, 398, 203,  40, 457, 498, 351, 440, 312, 267, 439, 203,\n",
       "         497, 243, 143,  67,  89, 333, 267, 461, 143,  18,  54, 327, 433]),\n",
       " tensor([310,  13]),\n",
       " tensor([316,  84, 428, 150,  77, 451, 349,  46,  66,  24]),\n",
       " tensor([440, 220, 316]),\n",
       " tensor([440, 220, 472]),\n",
       " tensor([ 35,  22, 130, 215, 261, 401, 210, 326,  26]),\n",
       " tensor([ 19, 215, 371, 215, 125, 353,  56, 355, 324, 362, 385, 383, 485, 125,\n",
       "         362,  50]),\n",
       " tensor([236, 105, 445, 266, 229, 137, 428, 107,  72]),\n",
       " tensor([220]),\n",
       " tensor([135, 274, 349, 297,  66,  49, 119, 380,  19, 270,  92, 232,  66]),\n",
       " tensor([103, 316]),\n",
       " tensor([213, 100, 158, 460, 223, 478, 317]),\n",
       " tensor([310, 120, 305, 103, 316]),\n",
       " tensor([331, 244, 306]),\n",
       " tensor([249,  29, 125, 442, 142, 460, 314, 160, 434]),\n",
       " tensor([461, 291, 477, 473, 162, 404, 347,  62,  77]),\n",
       " tensor([311, 361, 206,  12, 391, 369, 487]),\n",
       " tensor([358, 416, 363, 356,  77,  66, 425, 205, 404, 373,  57, 230]),\n",
       " tensor([55, 58, 22]),\n",
       " tensor([496, 291, 491, 477, 404,  77]),\n",
       " tensor([32]),\n",
       " tensor([ 35, 439, 149, 317, 167, 239, 278]),\n",
       " tensor([316]),\n",
       " tensor([472,  75, 197]),\n",
       " tensor([316, 285, 486, 322, 220]),\n",
       " tensor([316, 451, 433, 292]),\n",
       " tensor([365]),\n",
       " tensor([225,   3, 123,  48]),\n",
       " tensor([310, 490]),\n",
       " tensor([316, 285, 241, 395, 451]),\n",
       " tensor([352,  66, 289, 460,  87, 472, 107, 145, 232,  66, 430, 105]),\n",
       " tensor([414, 476, 464, 453, 284,  32,  54, 170, 374, 221,  25, 101, 510, 155,\n",
       "         377, 258, 405, 155,  89, 260, 506,  45, 336, 343,  89, 411, 403, 155,\n",
       "         421, 343, 127, 367,  32,   8, 179, 182, 266, 466, 144, 313, 127,  17,\n",
       "          89, 444, 469, 475, 348, 221, 293]),\n",
       " tensor([275, 188, 159, 413,  59]),\n",
       " tensor([ 80, 140, 271, 433]),\n",
       " tensor([ 16,  53,  22, 440, 334, 158, 319]),\n",
       " tensor([316, 375, 500,   2]),\n",
       " tensor([316]),\n",
       " tensor([255]),\n",
       " tensor([ 65, 158, 381, 409,  92, 501]),\n",
       " tensor([456,  77,  36, 217,  43, 491, 393, 477,  77]),\n",
       " tensor([231, 265,   6, 169]),\n",
       " tensor([225, 172,  70, 462,  47]),\n",
       " tensor([320, 109,  60, 489, 129, 354, 467, 320,  66, 109,  71, 259, 454, 332,\n",
       "         235,  42, 301,  52, 454, 454,  71, 301, 441,  71, 504, 114,  52, 259,\n",
       "          71]),\n",
       " tensor([103, 316]),\n",
       " tensor([246, 443, 252, 378, 215, 147]),\n",
       " tensor([ 14, 384, 338, 244, 306]),\n",
       " tensor([215, 213, 479, 198, 110, 208, 198, 345]),\n",
       " tensor([357, 431, 279,  73, 268,  20, 488, 455, 513]),\n",
       " tensor([171, 347, 417, 211, 307, 375,  44, 167, 507, 441, 245, 387, 501, 232,\n",
       "         507, 441, 235, 259, 463, 211, 307, 375, 449, 167, 507, 301, 481, 307,\n",
       "         167, 459, 339, 507, 301, 372, 418, 124, 507, 441, 492,  95, 489, 118,\n",
       "          23]),\n",
       " tensor([204, 359,  66, 224, 273, 394, 440, 171, 347, 147, 215, 375, 507, 441,\n",
       "         334, 183, 273, 400, 123,   5,  34,  92, 161, 394]),\n",
       " tensor([438]),\n",
       " tensor([32]),\n",
       " tensor([372,   2, 202, 316, 148, 271, 120, 322, 360, 202]),\n",
       " tensor([241,   1]),\n",
       " tensor([ 65, 158,  81,  19, 347]),\n",
       " tensor([440, 270, 365]),\n",
       " tensor([440, 220, 316]),\n",
       " tensor([365,  32, 357, 435, 159, 460, 216, 271,  47, 242,  66, 135, 373,  99,\n",
       "         426, 274, 355,  86,  85, 373,  99,  15, 296]),\n",
       " tensor([357, 237, 219, 249, 145, 173, 105]),\n",
       " tensor([201, 446, 424, 222, 189, 315,  63, 406, 264,  77, 212, 214]),\n",
       " tensor([201,  38,   9, 166, 427, 178]),\n",
       " tensor([248,  86,  85, 107,  97, 513, 200, 158,  53,  22, 337,  68, 335,  96,\n",
       "         157]),\n",
       " tensor([115,  61]),\n",
       " tensor([483, 162, 241, 126, 224,   4, 510, 206,  89, 392, 109, 196, 185, 404,\n",
       "         215]),\n",
       " tensor([329, 215, 404, 477, 184, 512, 477, 162, 397,  76, 493, 256, 512, 260,\n",
       "         233,  85, 329, 330, 180]),\n",
       " tensor([472, 422]),\n",
       " tensor([201, 433]),\n",
       " tensor([472, 232, 263, 440, 220]),\n",
       " tensor([153, 277, 287, 138, 132, 265, 499,  66, 147]),\n",
       " tensor([440, 299, 102, 394, 482, 399, 162,  82, 412,  62, 347, 415,  77]),\n",
       " tensor([340, 111, 323, 429, 190, 448]),\n",
       " tensor([237, 484, 286]),\n",
       " tensor([  8, 194, 491, 477, 215, 139, 300, 468, 341, 494,  30, 489, 108, 194,\n",
       "         423, 215, 511,  37, 351,  93, 468, 370, 460, 194, 370, 340]),\n",
       " tensor([220]),\n",
       " tensor([477,  13, 175, 164, 171, 347, 171,  77, 514,  13,  27,  12, 168, 228,\n",
       "         294, 234, 396, 480, 325, 298]),\n",
       " tensor([120, 122, 372,  10, 505, 273, 242, 109, 440,  14,  94, 133, 295,  10,\n",
       "         271, 246, 392, 273, 308, 177]),\n",
       " tensor([254, 156, 474, 112, 351, 198,  79,   2, 208, 345, 304, 168, 198, 110,\n",
       "         447, 419, 440, 152, 513, 508, 251, 447, 220, 215]),\n",
       " tensor([272, 472, 134, 342, 282]),\n",
       " tensor([120,  66, 379, 470, 302, 151, 176, 451,  54, 146, 276, 165, 309,   7,\n",
       "         407, 451, 163, 440, 172, 202, 271, 451, 271, 355, 120, 471,  41, 382,\n",
       "          66]),\n",
       " tensor([496, 286,  47, 390, 155, 322, 299, 116, 496, 113, 416,  11,  35, 346,\n",
       "         226, 290,  11, 389, 286]),\n",
       " tensor([  1, 362]),\n",
       " tensor([120, 218, 201]),\n",
       " tensor([104, 201, 104, 201, 198, 110, 366, 141, 465, 201,  91, 151, 368,  78,\n",
       "         198, 110]),\n",
       " tensor([358, 346,  47,  66]),\n",
       " tensor([440, 389, 495, 450,  19, 347, 426,  77]),\n",
       " tensor([472, 232]),\n",
       " tensor([220, 201, 433]),\n",
       " tensor([440, 220,  32]),\n",
       " tensor([ 0, 83]),\n",
       " tensor([254, 141,  47,  66, 250, 227, 328,  98, 472, 237,  92, 318, 240, 266,\n",
       "         281, 170, 509, 285,  66, 440,  97, 262, 366,  47, 288, 432, 389, 154,\n",
       "         285,  66, 280,  66, 151, 355, 181, 215, 404]),\n",
       " tensor([461, 477, 128,   2]),\n",
       " tensor([254, 141, 344, 496, 303,  54, 410, 131, 413, 460, 364, 193, 458, 294,\n",
       "         166,  74, 396, 420,  64, 408, 186,  28, 199, 402]),\n",
       " tensor([ 32, 484, 195]),\n",
       " tensor([187,  66, 373, 247,  69, 220, 428, 201, 322, 220]),\n",
       " tensor([ 80, 317, 439]),\n",
       " tensor([350, 321,   7, 257, 503,  33,  82, 412, 193, 347, 321, 191, 257, 503,\n",
       "         329,  74, 396,  23]),\n",
       " tensor([ 39, 388, 402,  21]),\n",
       " tensor([440, 151, 383, 439,  51, 386, 117, 106,  88, 239, 327, 308])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AA = list(map(lambda x: list(map(lambda a: word_to_ix[a], x.split(' '))), prepro_text))\n",
    "word_list_tensor = list(map(lambda x: torch.tensor(x), AA))\n",
    "word_list_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentences=word_list, min_count=1, vector_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31056544, -0.28431976,  0.26446304, ..., -0.3733835 ,\n",
       "        -0.15181595, -0.1568166 ],\n",
       "       [-0.21347629, -0.3450036 ,  0.25862765, ..., -0.37762025,\n",
       "        -0.12052578, -0.19990642],\n",
       "       [-0.28328174, -0.29868165,  0.28039896, ..., -0.3619463 ,\n",
       "        -0.10685853, -0.12507077],\n",
       "       ...,\n",
       "       [ 0.03028108, -0.02904218,  0.02877627, ...,  0.02320009,\n",
       "        -0.00092264,  0.02302395],\n",
       "       [-0.28231737, -0.32727784,  0.45453632, ..., -0.34966093,\n",
       "        -0.20397404, -0.06953479],\n",
       "       [-0.28342745, -0.3251203 ,  0.42236415, ..., -0.32388267,\n",
       "        -0.17760906, -0.02318389]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(new_df[\"reason_category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad = pad_sequence(word_list_tensor, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 55])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pad.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = TensorDataset(X_train, torch.from_numpy(y_train).type(torch.long))\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_len = 30\n",
    "hidden_dim = 30\n",
    "n_layers=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(count_vocab), embedding_dim=embed_len)\n",
    "        self.rnn = nn.RNN(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 15)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        embeddings = self.embedding_layer(X_batch)\n",
    "        output1, hidden = self.rnn(embeddings, torch.randn(1, len(X_batch), hidden_dim))\n",
    "        print(hidden.size(), \"HIDDEN\")\n",
    "        print(output1.size(), \"OUT1\")\n",
    "        output2 = self.linear(output1)\n",
    "        log_probs = self.softmax(output2)\n",
    "        return torch.argmax(log_probs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embedding_layer): Embedding(515, 30)\n",
       "  (rnn): RNN(30, 30, batch_first=True)\n",
       "  (linear): Linear(in_features=30, out_features=15, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 30]) HIDDEN\n",
      "torch.Size([80, 55, 30]) OUT1\n",
      "torch.Size([55, 15])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (55) to match target batch_size (80).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\NLP_5_sem\\lab2.ipynb Cell 40\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X54sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(x_b)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X54sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(outputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X54sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m loss_value \u001b[39m=\u001b[39m loss_function(outputs, y_b)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss_value\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\NLP_5_sem\\venv_nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\NLP_5_sem\\venv_nlp\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:216\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnll_loss(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32md:\\NLP_5_sem\\venv_nlp\\Lib\\site-packages\\torch\\nn\\functional.py:2704\u001b[0m, in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2702\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2703\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 2704\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mnll_loss_nd(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (55) to match target batch_size (80)."
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "loss_values = []\n",
    "for epoch in range(epochs):\n",
    "    for x_b, y_b in train_dl:\n",
    "        outputs = model(x_b)\n",
    "        print(outputs.shape)\n",
    "        loss_value = loss_function(outputs, y_b)\n",
    "\n",
    "        loss_value.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    loss_values.append(loss_value.item())\n",
    "\n",
    "    print(f'Эпоха {epoch + 1}, Значение функции потерь: {loss_value.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(count_vocab), embedding_dim=embed_len)\n",
    "        self.rnn = nn.LSTM(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 15)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, X_batch):\n",
    "        \n",
    "        embeddings = self.embedding_layer(X_batch)\n",
    "        print(embeddings.size(), \"emb\")\n",
    "        output1, hidden = self.rnn(embeddings, torch.randn(1, len(X_batch), hidden_dim))\n",
    "        print(hidden.size(), \"HIDDEN\")\n",
    "        print(output1.size(), \"OUT1\")\n",
    "        output2 = self.linear(output1)\n",
    "        log_probs = self.softmax(output2).mean(1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LSTMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (embedding_layer): Embedding(614, 30)\n",
       "  (rnn): LSTM(30, 30, batch_first=True)\n",
       "  (linear): Linear(in_features=30, out_features=15, bias=True)\n",
       "  (softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 102, 30]) emb\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\NLP_5_sem\\lab2.ipynb Cell 45\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x_b, y_b \u001b[39min\u001b[39;00m train_dl:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         outputs2 \u001b[39m=\u001b[39m model2(x_b)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mprint\u001b[39m(outputs2\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         loss_value2 \u001b[39m=\u001b[39m loss_function(outputs2, y_b)\n",
      "File \u001b[1;32md:\\NLP_5_sem\\venv_nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\NLP_5_sem\\lab2.ipynb Cell 45\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_layer(X_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(embeddings\u001b[39m.\u001b[39msize(), \u001b[39m\"\u001b[39m\u001b[39memb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m output1, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(embeddings, torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(X_batch), hidden_dim))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(hidden\u001b[39m.\u001b[39msize(), \u001b[39m\"\u001b[39m\u001b[39mHIDDEN\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP_5_sem/lab2.ipynb#X62sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(output1\u001b[39m.\u001b[39msize(), \u001b[39m\"\u001b[39m\u001b[39mOUT1\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\NLP_5_sem\\venv_nlp\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\NLP_5_sem\\venv_nlp\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:797\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[39mif\u001b[39;00m is_batched:\n\u001b[0;32m    795\u001b[0m     \u001b[39mif\u001b[39;00m (hx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mor\u001b[39;00m hx[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m):\n\u001b[0;32m    796\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mFor batched 3-D input, hx and cx should \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 797\u001b[0m                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39malso be 3-D but got (\u001b[39m\u001b[39m{\u001b[39;00mhx[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D, \u001b[39m\u001b[39m{\u001b[39;00mhx[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D) tensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    798\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    799\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "loss_values2 = []\n",
    "for epoch in range(epochs):\n",
    "    for x_b, y_b in train_dl:\n",
    "        outputs2 = model2(x_b)\n",
    "        print(outputs2.shape)\n",
    "        loss_value2 = loss_function(outputs2, y_b)\n",
    "\n",
    "        loss_value2.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    loss_values2.append(loss_value2.item())\n",
    "\n",
    "    print(f'Эпоха {epoch + 1}, Значение функции потерь: {loss_value2.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
